{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "from tensorflow.contrib import learn\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gzip\n",
    "from random import random\n",
    "from preprocess import MyVocabularyProcessor\n",
    "import sys\n",
    "import unicodedata\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from train_snli.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['a person on a horse jumps over a broken down airplane.',\n",
       "       'a person on a horse jumps over a broken down airplane.',\n",
       "       'there are children present', ...,\n",
       "       \"four kids won awards for 'cleanest feet'\",\n",
       "       'a man in a business suit is heading to a board meeting.',\n",
       "       'on the beautiful blue water there is a man in a bodysuit surfing.'],\n",
       "      dtype='<U402')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "from tensorflow.contrib import learn\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gzip\n",
    "from random import random\n",
    "from preprocess import MyVocabularyProcessor\n",
    "import sys\n",
    "\n",
    "\n",
    "def getDataSets(training_paths, max_document_length, percent_dev, batch_size, is_char_based):\n",
    "        if is_char_based:\n",
    "            x1_text, x2_text, y=self.getTsvDataCharBased(training_paths)\n",
    "        else:\n",
    "            x1_text, x2_text, y=self.getTsvData(training_paths)\n",
    "        # Build vocabulary\n",
    "        print(\"Building vocabulary\")\n",
    "        vocab_processor = MyVocabularyProcessor(max_document_length,min_frequency=0,is_char_based=is_char_based)\n",
    "        vocab_processor.fit_transform(np.concatenate((x2_text,x1_text),axis=0))\n",
    "        print(\"Length of loaded vocabulary ={}\".format( len(vocab_processor.vocabulary_)))\n",
    "        i1=0\n",
    "        train_set=[]\n",
    "        dev_set=[]\n",
    "        sum_no_of_batches = 0\n",
    "        x1 = np.asarray(list(vocab_processor.transform(x1_text)))\n",
    "        x2 = np.asarray(list(vocab_processor.transform(x2_text)))\n",
    "        # Randomly shuffle data\n",
    "        np.random.seed(131)\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "        x1_shuffled = x1[shuffle_indices]\n",
    "        x2_shuffled = x2[shuffle_indices]\n",
    "        y_shuffled = y[shuffle_indices]\n",
    "        dev_idx = -1*len(y_shuffled)*percent_dev//100\n",
    "        del x1\n",
    "        del x2\n",
    "        # Split train/test set\n",
    "        self.dumpValidation(x1_text,x2_text,y,shuffle_indices,dev_idx,0)\n",
    "        # TODO: This is very crude, should use cross-validation\n",
    "        x1_train, x1_dev = x1_shuffled[:dev_idx], x1_shuffled[dev_idx:]\n",
    "        x2_train, x2_dev = x2_shuffled[:dev_idx], x2_shuffled[dev_idx:]\n",
    "        y_train, y_dev = y_shuffled[:dev_idx], y_shuffled[dev_idx:]\n",
    "        print(\"Train/Dev split for {}: {:d}/{:d}\".format(training_paths, len(y_train), len(y_dev)))\n",
    "        sum_no_of_batches = sum_no_of_batches+(len(y_train)//batch_size)\n",
    "        train_set=(x1_train,x2_train,y_train)\n",
    "        dev_set=(x1_dev,x2_dev,y_dev)\n",
    "        gc.collect()\n",
    "        return train_set,dev_set,vocab_processor,sum_no_of_batches\n",
    "def getTsvData( filepath):\n",
    "    print(\"Loading training data from \"+filepath)\n",
    "    x1=[]\n",
    "    x2=[]\n",
    "    y=[]\n",
    "    # positive samples from file\n",
    "    for line in open(filepath):\n",
    "        l=line.strip().split(\"\\t\")\n",
    "        if len(l)<2:\n",
    "            continue\n",
    "        if random() > 0.5:\n",
    "            x1.append(l[0].lower())\n",
    "            x2.append(l[1].lower())\n",
    "        else:\n",
    "            x1.append(l[1].lower())\n",
    "            x2.append(l[0].lower())\n",
    "        y.append(int(l[2]))\n",
    "    return np.asarray(x1),np.asarray(x2),np.asarray(y)\n",
    "\n",
    "def getTsvDataCharBased(filepath):\n",
    "    print(\"Loading training data from \"+filepath)\n",
    "    x1=[]\n",
    "    x2=[]\n",
    "    y=[]\n",
    "    # positive samples from file\n",
    "    for line in open(filepath):\n",
    "        l=line.strip().split(\"\\t\")\n",
    "        if len(l)<2:\n",
    "            continue\n",
    "        if random() > 0.5:\n",
    "           x1.append(l[0].lower())\n",
    "           x2.append(l[1].lower())\n",
    "        else:\n",
    "           x1.append(l[1].lower())\n",
    "           x2.append(l[0].lower())\n",
    "        y.append(1)#np.array([0,1]))\n",
    "    # generate random negative samples\n",
    "    combined = np.asarray(x1+x2)\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(combined)))\n",
    "    combined_shuff = combined[shuffle_indices]\n",
    "    for i in xrange(len(combined)):\n",
    "        x1.append(combined[i])\n",
    "        x2.append(combined_shuff[i])\n",
    "        y.append(0) #np.array([1,0]))\n",
    "    return np.asarray(x1),np.asarray(x2),np.asarray(y)\n",
    "\n",
    "filepath=\"train_snli.txt\"\n",
    "x1_text, x2_text, y=getTsvData(filepath)\n",
    "x1_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z0-9.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "filepath=\"train_snli1.txt\"\n",
    "lines=open(filepath,encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a person on a horse jumps over a broken down airplane .',\n",
       "  'a person is at a diner ordering an omelette .',\n",
       "  '0'],\n",
       " ['a person on a horse jumps over a broken down airplane .',\n",
       "  'a person is outdoors on a horse .',\n",
       "  '1'],\n",
       " ['children smiling and waving at camera', 'there are children present', '1'],\n",
       " ['children smiling and waving at camera', 'the kids are frowning', '0'],\n",
       " ['a boy is jumping on skateboard in the middle of a red bridge .',\n",
       "  'the boy skates down the sidewalk .',\n",
       "  '0'],\n",
       " ['a boy is jumping on skateboard in the middle of a red bridge .',\n",
       "  'the boy does a skateboarding trick .',\n",
       "  '1'],\n",
       " ['an older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background .',\n",
       "  'a boy flips a burger .',\n",
       "  '0'],\n",
       " ['two blond women are hugging one another .',\n",
       "  'the women are sleeping .',\n",
       "  '0'],\n",
       " ['two blond women are hugging one another .',\n",
       "  'there are women showing affection .',\n",
       "  '1'],\n",
       " ['a few people in a restaurant setting one of them is drinking orange juice .',\n",
       "  'the people are sitting at desks in school .',\n",
       "  '0'],\n",
       " ['a few people in a restaurant setting one of them is drinking orange juice .',\n",
       "  'the diners are at a restaurant .',\n",
       "  '1'],\n",
       " ['an older man is drinking orange juice at a restaurant .',\n",
       "  'a man is drinking juice .',\n",
       "  '1'],\n",
       " ['an older man is drinking orange juice at a restaurant .',\n",
       "  'two women are at a restaurant drinking wine .',\n",
       "  '0'],\n",
       " ['a man with blond hair and a brown shirt drinking out of a public water fountain .',\n",
       "  'a blond man wearing a brown shirt is reading a book on a bench in the park',\n",
       "  '0'],\n",
       " ['a man with blond hair and a brown shirt drinking out of a public water fountain .',\n",
       "  'a blond man drinking water from a fountain .',\n",
       "  '1'],\n",
       " ['two women who just had lunch hugging and saying goodbye .',\n",
       "  'the friends scowl at each other over a full dinner table .',\n",
       "  '0'],\n",
       " ['two women who just had lunch hugging and saying goodbye .',\n",
       "  'there are two woman in this picture .',\n",
       "  '1'],\n",
       " ['two women holding food carryout containers hug .',\n",
       "  'two groups of rival gang members flipped each other off .',\n",
       "  '0'],\n",
       " ['two women holding food carryout containers hug .',\n",
       "  'two women hug each other .',\n",
       "  '1'],\n",
       " ['a little league team tries to catch a runner sliding into a base in an afternoon game .',\n",
       "  'a team is trying to tag a runner out .',\n",
       "  '1'],\n",
       " ['a little league team tries to catch a runner sliding into a base in an afternoon game .',\n",
       "  'a team is playing baseball on saturn .',\n",
       "  '0']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
